{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flair.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1lr7I8CF15Mex3pwQbCiqmxCbfhfCZP89",
      "authorship_tag": "ABX9TyPVmfg6H1JjC+7jwSF3MLZF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankaran45/CliNER/blob/master/Flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIpx_9BbETXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9ea7e4a-d965-4cf2-9275-ccfd5524ce4d"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/29/81e3c9a829ec50857c23d82560941625f6b42ce76ee7c56ea9529e959d18/flair-0.4.5-py3-none-any.whl (136kB)\n",
            "\r\u001b[K     |██▍                             | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 81kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 92kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
            "Collecting bpemb>=0.2.9\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 44.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.38.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/46/d1/ac3a649a24542850e281cfefb9024ba4ba174157713015b6489a593806fe/Deprecated-1.2.8-py2.py3-none-any.whl\n",
            "Collecting transformers>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 45.7MB/s \n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
            "Collecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/e2/c19c667f42f72716a7d03e8dd4d6f63f47d39feadd44cc1ee7ca3089862c/pytest-5.4.1-py3-none-any.whl (246kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (1.18.2)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.10.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.10.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (1.12.34)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 45.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 29.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.7)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.1.9)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (8.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2019.11.28)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (1.18.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.34 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (1.15.34)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.9.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.3.0->flair) (7.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.1.0)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.4.1)\n",
            "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (1.7.2)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (1.0.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.34->boto3->transformers>=2.3.0->flair) (0.15.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (46.1.3)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (4.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (1.16.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (0.4.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (1.51.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (3.10.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.2.1->gensim>=3.4.0->flair) (2018.9)\n",
            "Building wheels for collected packages: segtok, mpld3, langdetect, sqlitedict, sacremoses\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.7-cp36-none-any.whl size=23258 sha256=4abc5dce3a17f5d272e23fe17db5b54636a21f51330cd4361e7d8b99597d5364\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116679 sha256=393d63a67185a199593b7b8a351423d40440d4db6ed20784407d6bc1a05be430\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=1909e2c677870c109bf4b9b82aacd8fc6f40505b4542119482bde2961556edd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp36-none-any.whl size=14689 sha256=0cb61ca186f772723b307ce858821612da0590cf4bd78c042bbf7f9795555142\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=47a972ff29f643e746f6c1a350b887c600a1bda8a33efa5626dd2811ce6dd770\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built segtok mpld3 langdetect sqlitedict sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: segtok, sentencepiece, bpemb, mpld3, langdetect, deprecated, tokenizers, sacremoses, transformers, sqlitedict, pluggy, pytest, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.0 deprecated-1.2.8 flair-0.4.5 langdetect-1.0.8 mpld3-0.3 pluggy-0.13.1 pytest-5.4.1 sacremoses-0.0.38 segtok-1.5.7 sentencepiece-0.1.85 sqlitedict-1.6.0 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKGeS7RQoNnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/topic-segmentation/athi_dataset/*.csv ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-N-VP7KocZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data_tr = pd.read_csv(\"./trainingset.csv\")\n",
        "data_te = pd.read_csv(\"./testset.csv\")\n",
        "data = pd.concat([data_tr, data_te]).sample(frac=1, random_state=13).drop_duplicates()\n",
        "data['label'] = '__label__' + data['label'].astype(str)\n",
        "data.iloc[0:int(len(data)*0.8)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
        "data.iloc[int(len(data)*0.8):int(len(data)*0.9)].to_csv('test.csv', sep='\\t', index = False, header = False)\n",
        "data.iloc[int(len(data)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHxJCwfjrsbl",
        "colab_type": "text"
      },
      "source": [
        "Word Embeddings: Glove\n",
        "Contextual string embeddings capture latent information that allows us to go \n",
        "beyond the notion of words. They enable modeling words as sequences of characters,\n",
        "further, they allow contextualization based on their surrounding text. This way\n",
        "same word will have different embeddings depending on the sentence context.\n",
        "\n",
        "These embeddings are then combined together to create a stacking layer. Glove, Forward, Backward, Bert, Cui2Vec embeddings are thus combined in various order and analyzed.\n",
        "\n",
        "Document embeddings give one embedding for the entire text, whereas word embeddings operate at the word level. One way to do this is using a pooling operation over word embeddings in the document. Pooling uses mean of the words in the sentence to create a sentence level document embedding.\n",
        "\n",
        "Min/Max Pooling can also be used. Further before the word embeddings get pooled a non-linear transformation can also be applied.\n",
        "\n",
        "The other way to do this document embedding is to use a RNN that combines the word embeddings to create a sentence level embedding. RNN can be GRU or LSTM. Essentially the word embeddings of the token in the document are taken as input and the last output state of the network is used as document embedding. Furthermore, as is common in sequence classification, we can use a Bidirectional RNN to consider the sentence homogenously forward and backawrd.\n",
        "\n",
        "Thus we get a dizzying array of embedding choices:\n",
        "\n",
        "1. Word Embeddings: Glove, Word2Vec, Cui2Vec, BERT, Flair Forward/Backward\n",
        "2. Document Embeddings: Simple Mean/Min/Max Pooling with Linear/Non-Linear transformations. RNN-based embeddings using Simple RNN, GRU, LSTM. Bi-directional variations thereof."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Psj1YvUuP1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "e08b04dc-4fd5-4f8a-fd50-ef201c570619"
      },
      "source": [
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "# Configuration  for WordEmbeddings\n",
        "word_embeddings = [\n",
        "                    WordEmbeddings('glove'),\n",
        "                    FlairEmbeddings('news-forward-fast'),\n",
        "                    FlairEmbeddings('news-backward-fast'),\n",
        "                    #BertEmbeddings('bert-base-multilingual-cased')\n",
        "                    ]\n",
        "\n",
        "stacked_word_embeddings = StackedEmbeddings(word_embeddings)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 08:52:43,213 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpuo4_0d70\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:10<00:00, 14732864.70B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 08:52:54,765 copying /tmp/tmpuo4_0d70 to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 08:52:54,946 removing temp file /tmp/tmpuo4_0d70\n",
            "2020-04-07 08:52:58,355 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmptt51m3yt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:02<00:00, 9421344.18B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 08:53:01,295 copying /tmp/tmptt51m3yt to cache at /root/.flair/embeddings/glove.gensim\n",
            "2020-04-07 08:53:01,322 removing temp file /tmp/tmptt51m3yt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 08:53:03,667 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp2vyo9e_v\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:02<00:00, 9524824.98B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 08:53:06,446 copying /tmp/tmp2vyo9e_v to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2020-04-07 08:53:06,471 removing temp file /tmp/tmp2vyo9e_v\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 08:53:23,506 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp5pvlbt56\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:01<00:00, 10002892.26B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 08:53:26,159 copying /tmp/tmp5pvlbt56 to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 08:53:26,186 removing temp file /tmp/tmp5pvlbt56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcSQ7lxaudeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.embeddings import DocumentPoolEmbeddings, DocumentRNNEmbeddings, DocumentLSTMEmbeddings\n",
        "\n",
        "# Case 1: Pooling of word embeddings\n",
        "# Add pooling='min' for min pooling, 'max' for max pooling, and fine_tune_mode='nonlinear' to try \n",
        "#document_embeddings = DocumentPoolEmbeddings(word_embeddings)\n",
        "\n",
        "# Case 2: RNN\n",
        "#document_embeddings = DocumentRNNEmbeddings(word_embeddings)\n",
        "document_embeddings = DocumentRNNEmbeddings(word_embeddings, rnn_type='LSTM', bidirectional=True, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAKrA0yIqabd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "170e38ee-c334-4a37-db8d-d6d85e88d7c9"
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('./'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
        "\n",
        "classifier_embeddings = document_embeddings\n",
        "\n",
        "\n",
        "#document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier = TextClassifier(classifier_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train('./', max_epochs=25, checkpoint=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 09:04:21,527 Reading data from .\n",
            "2020-04-07 09:04:21,529 Train: train.csv\n",
            "2020-04-07 09:04:21,530 Dev: dev.csv\n",
            "2020-04-07 09:04:21,531 Test: test.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated function (or staticmethod) load_classification_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 09:04:26,475 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13604/13604 [00:00<00:00, 244504.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 09:04:26,534 [b'HOSPITAL_COURSE', b'MEDICATIONS', b'PHYSICAL_EXAMINATION', b'HISTORY_PRESENT_ILLNESS']\n",
            "2020-04-07 09:04:26,541 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:04:26,542 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): LSTM(256, 512, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=2048, out_features=4, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-04-07 09:04:26,544 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:04:26,545 Corpus: \"Corpus: 13604 train + 1701 dev + 1701 test sentences\"\n",
            "2020-04-07 09:04:26,546 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:04:26,547 Parameters:\n",
            "2020-04-07 09:04:26,549  - learning_rate: \"0.1\"\n",
            "2020-04-07 09:04:26,550  - mini_batch_size: \"32\"\n",
            "2020-04-07 09:04:26,551  - patience: \"3\"\n",
            "2020-04-07 09:04:26,552  - anneal_factor: \"0.5\"\n",
            "2020-04-07 09:04:26,554  - max_epochs: \"25\"\n",
            "2020-04-07 09:04:26,555  - shuffle: \"True\"\n",
            "2020-04-07 09:04:26,557  - train_with_dev: \"False\"\n",
            "2020-04-07 09:04:26,558  - batch_growth_annealing: \"False\"\n",
            "2020-04-07 09:04:26,560 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:04:26,561 Model training base path: \".\"\n",
            "2020-04-07 09:04:26,563 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:04:26,564 Device: cuda:0\n",
            "2020-04-07 09:04:26,566 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:04:26,567 Embeddings storage mode: cpu\n",
            "2020-04-07 09:04:26,569 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 09:04:33,709 epoch 1 - iter 42/426 - loss 1.22046021 - samples/sec: 188.37\n",
            "2020-04-07 09:04:41,032 epoch 1 - iter 84/426 - loss 1.14956590 - samples/sec: 184.42\n",
            "2020-04-07 09:04:48,605 epoch 1 - iter 126/426 - loss 1.08903304 - samples/sec: 178.18\n",
            "2020-04-07 09:04:56,515 epoch 1 - iter 168/426 - loss 1.04638967 - samples/sec: 170.53\n",
            "2020-04-07 09:05:04,402 epoch 1 - iter 210/426 - loss 1.01610473 - samples/sec: 171.02\n",
            "2020-04-07 09:05:13,669 epoch 1 - iter 252/426 - loss 0.99237850 - samples/sec: 145.49\n",
            "2020-04-07 09:05:19,333 epoch 1 - iter 294/426 - loss 0.97010220 - samples/sec: 238.52\n",
            "2020-04-07 09:05:25,031 epoch 1 - iter 336/426 - loss 0.94993618 - samples/sec: 237.03\n",
            "2020-04-07 09:05:30,575 epoch 1 - iter 378/426 - loss 0.92864602 - samples/sec: 243.68\n",
            "2020-04-07 09:05:36,634 epoch 1 - iter 420/426 - loss 0.91552568 - samples/sec: 222.86\n",
            "2020-04-07 09:05:37,568 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:05:37,569 EPOCH 1 done: loss 0.9130 - lr 0.1000\n",
            "2020-04-07 09:05:44,967 DEV : loss 0.7704495191574097 - score 0.6467\n",
            "2020-04-07 09:05:45,088 BAD EPOCHS (no improvement): 0\n",
            "2020-04-07 09:05:51,435 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:05:54,161 epoch 2 - iter 42/426 - loss 0.81095640 - samples/sec: 493.80\n",
            "2020-04-07 09:05:56,897 epoch 2 - iter 84/426 - loss 0.80501758 - samples/sec: 496.10\n",
            "2020-04-07 09:05:59,737 epoch 2 - iter 126/426 - loss 0.77417485 - samples/sec: 478.25\n",
            "2020-04-07 09:06:02,468 epoch 2 - iter 168/426 - loss 0.76964212 - samples/sec: 497.57\n",
            "2020-04-07 09:06:05,205 epoch 2 - iter 210/426 - loss 0.76601527 - samples/sec: 496.31\n",
            "2020-04-07 09:06:08,078 epoch 2 - iter 252/426 - loss 0.75170021 - samples/sec: 472.37\n",
            "2020-04-07 09:06:10,922 epoch 2 - iter 294/426 - loss 0.74455669 - samples/sec: 477.44\n",
            "2020-04-07 09:06:13,648 epoch 2 - iter 336/426 - loss 0.74208323 - samples/sec: 498.24\n",
            "2020-04-07 09:06:16,486 epoch 2 - iter 378/426 - loss 0.73811410 - samples/sec: 478.37\n",
            "2020-04-07 09:06:19,299 epoch 2 - iter 420/426 - loss 0.73527903 - samples/sec: 483.29\n",
            "2020-04-07 09:06:19,685 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:06:19,686 EPOCH 2 done: loss 0.7343 - lr 0.1000\n",
            "2020-04-07 09:06:22,453 DEV : loss 0.7318400144577026 - score 0.7125\n",
            "2020-04-07 09:06:22,575 BAD EPOCHS (no improvement): 0\n",
            "2020-04-07 09:06:28,873 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:06:31,571 epoch 3 - iter 42/426 - loss 0.71358423 - samples/sec: 499.07\n",
            "2020-04-07 09:06:34,439 epoch 3 - iter 84/426 - loss 0.68652490 - samples/sec: 473.72\n",
            "2020-04-07 09:06:37,340 epoch 3 - iter 126/426 - loss 0.69467448 - samples/sec: 467.83\n",
            "2020-04-07 09:06:40,236 epoch 3 - iter 168/426 - loss 0.69508541 - samples/sec: 468.99\n",
            "2020-04-07 09:06:43,072 epoch 3 - iter 210/426 - loss 0.68514127 - samples/sec: 478.72\n",
            "2020-04-07 09:06:45,922 epoch 3 - iter 252/426 - loss 0.68671090 - samples/sec: 476.41\n",
            "2020-04-07 09:06:48,878 epoch 3 - iter 294/426 - loss 0.68737230 - samples/sec: 459.33\n",
            "2020-04-07 09:06:51,803 epoch 3 - iter 336/426 - loss 0.68544347 - samples/sec: 464.12\n",
            "2020-04-07 09:06:54,695 epoch 3 - iter 378/426 - loss 0.69008045 - samples/sec: 469.63\n",
            "2020-04-07 09:06:57,633 epoch 3 - iter 420/426 - loss 0.69051297 - samples/sec: 461.91\n",
            "2020-04-07 09:06:58,028 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:06:58,029 EPOCH 3 done: loss 0.6900 - lr 0.1000\n",
            "2020-04-07 09:07:00,785 DEV : loss 0.7250925898551941 - score 0.7108\n",
            "2020-04-07 09:07:00,908 BAD EPOCHS (no improvement): 1\n",
            "2020-04-07 09:07:04,006 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:07:06,799 epoch 4 - iter 42/426 - loss 0.66501721 - samples/sec: 481.92\n",
            "2020-04-07 09:07:09,570 epoch 4 - iter 84/426 - loss 0.65862169 - samples/sec: 490.04\n",
            "2020-04-07 09:07:12,439 epoch 4 - iter 126/426 - loss 0.66258559 - samples/sec: 473.39\n",
            "2020-04-07 09:07:15,245 epoch 4 - iter 168/426 - loss 0.66401828 - samples/sec: 484.18\n",
            "2020-04-07 09:07:18,005 epoch 4 - iter 210/426 - loss 0.66192206 - samples/sec: 492.15\n",
            "2020-04-07 09:07:20,767 epoch 4 - iter 252/426 - loss 0.66256802 - samples/sec: 491.64\n",
            "2020-04-07 09:07:23,609 epoch 4 - iter 294/426 - loss 0.66007575 - samples/sec: 477.96\n",
            "2020-04-07 09:07:26,402 epoch 4 - iter 336/426 - loss 0.66305758 - samples/sec: 486.52\n",
            "2020-04-07 09:07:29,219 epoch 4 - iter 378/426 - loss 0.66764994 - samples/sec: 482.31\n",
            "2020-04-07 09:07:32,072 epoch 4 - iter 420/426 - loss 0.66150148 - samples/sec: 475.94\n",
            "2020-04-07 09:07:32,454 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:07:32,456 EPOCH 4 done: loss 0.6632 - lr 0.1000\n",
            "2020-04-07 09:07:35,209 DEV : loss 0.6650142669677734 - score 0.7454\n",
            "2020-04-07 09:07:35,332 BAD EPOCHS (no improvement): 0\n",
            "2020-04-07 09:07:41,472 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:07:44,271 epoch 5 - iter 42/426 - loss 0.65868625 - samples/sec: 480.97\n",
            "2020-04-07 09:07:47,176 epoch 5 - iter 84/426 - loss 0.65917632 - samples/sec: 467.13\n",
            "2020-04-07 09:07:50,057 epoch 5 - iter 126/426 - loss 0.65109863 - samples/sec: 471.17\n",
            "2020-04-07 09:07:52,919 epoch 5 - iter 168/426 - loss 0.65649053 - samples/sec: 474.42\n",
            "2020-04-07 09:07:55,770 epoch 5 - iter 210/426 - loss 0.65443651 - samples/sec: 476.27\n",
            "2020-04-07 09:07:58,482 epoch 5 - iter 252/426 - loss 0.65123221 - samples/sec: 500.26\n",
            "2020-04-07 09:08:01,333 epoch 5 - iter 294/426 - loss 0.65172764 - samples/sec: 476.30\n",
            "2020-04-07 09:08:04,082 epoch 5 - iter 336/426 - loss 0.64719310 - samples/sec: 495.11\n",
            "2020-04-07 09:08:06,852 epoch 5 - iter 378/426 - loss 0.64819854 - samples/sec: 490.01\n",
            "2020-04-07 09:08:09,619 epoch 5 - iter 420/426 - loss 0.64731111 - samples/sec: 490.90\n",
            "2020-04-07 09:08:10,032 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:08:10,033 EPOCH 5 done: loss 0.6474 - lr 0.1000\n",
            "2020-04-07 09:08:12,786 DEV : loss 0.8901962637901306 - score 0.7125\n",
            "2020-04-07 09:08:12,912 BAD EPOCHS (no improvement): 1\n",
            "2020-04-07 09:08:15,969 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:08:18,719 epoch 6 - iter 42/426 - loss 0.67086373 - samples/sec: 489.51\n",
            "2020-04-07 09:08:21,537 epoch 6 - iter 84/426 - loss 0.64594883 - samples/sec: 482.27\n",
            "2020-04-07 09:08:24,367 epoch 6 - iter 126/426 - loss 0.63387313 - samples/sec: 479.57\n",
            "2020-04-07 09:08:27,244 epoch 6 - iter 168/426 - loss 0.61853030 - samples/sec: 471.64\n",
            "2020-04-07 09:08:30,071 epoch 6 - iter 210/426 - loss 0.62191063 - samples/sec: 480.78\n",
            "2020-04-07 09:08:32,904 epoch 6 - iter 252/426 - loss 0.62107558 - samples/sec: 479.36\n",
            "2020-04-07 09:08:35,726 epoch 6 - iter 294/426 - loss 0.62313969 - samples/sec: 481.20\n",
            "2020-04-07 09:08:38,578 epoch 6 - iter 336/426 - loss 0.62887716 - samples/sec: 476.01\n",
            "2020-04-07 09:08:41,430 epoch 6 - iter 378/426 - loss 0.62993676 - samples/sec: 476.20\n",
            "2020-04-07 09:08:44,294 epoch 6 - iter 420/426 - loss 0.63186186 - samples/sec: 473.93\n",
            "2020-04-07 09:08:44,649 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:08:44,650 EPOCH 6 done: loss 0.6304 - lr 0.1000\n",
            "2020-04-07 09:08:47,425 DEV : loss 0.6581447124481201 - score 0.7366\n",
            "2020-04-07 09:08:47,544 BAD EPOCHS (no improvement): 2\n",
            "2020-04-07 09:08:50,601 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:08:53,408 epoch 7 - iter 42/426 - loss 0.65786946 - samples/sec: 479.41\n",
            "2020-04-07 09:08:56,328 epoch 7 - iter 84/426 - loss 0.64254101 - samples/sec: 464.88\n",
            "2020-04-07 09:08:59,185 epoch 7 - iter 126/426 - loss 0.61676250 - samples/sec: 475.57\n",
            "2020-04-07 09:09:01,987 epoch 7 - iter 168/426 - loss 0.61897911 - samples/sec: 484.56\n",
            "2020-04-07 09:09:04,885 epoch 7 - iter 210/426 - loss 0.62452864 - samples/sec: 468.45\n",
            "2020-04-07 09:09:07,733 epoch 7 - iter 252/426 - loss 0.61922746 - samples/sec: 477.23\n",
            "2020-04-07 09:09:10,617 epoch 7 - iter 294/426 - loss 0.62343758 - samples/sec: 470.79\n",
            "2020-04-07 09:09:13,479 epoch 7 - iter 336/426 - loss 0.61670079 - samples/sec: 474.31\n",
            "2020-04-07 09:09:16,323 epoch 7 - iter 378/426 - loss 0.61511076 - samples/sec: 477.93\n",
            "2020-04-07 09:09:19,207 epoch 7 - iter 420/426 - loss 0.61659202 - samples/sec: 471.15\n",
            "2020-04-07 09:09:19,584 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:09:19,585 EPOCH 7 done: loss 0.6166 - lr 0.1000\n",
            "2020-04-07 09:09:22,394 DEV : loss 0.8219566941261292 - score 0.6649\n",
            "2020-04-07 09:09:22,521 BAD EPOCHS (no improvement): 3\n",
            "2020-04-07 09:09:25,670 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:09:28,444 epoch 8 - iter 42/426 - loss 0.61419992 - samples/sec: 485.26\n",
            "2020-04-07 09:09:31,174 epoch 8 - iter 84/426 - loss 0.62574471 - samples/sec: 497.37\n",
            "2020-04-07 09:09:34,051 epoch 8 - iter 126/426 - loss 0.61525033 - samples/sec: 471.77\n",
            "2020-04-07 09:09:37,724 epoch 8 - iter 168/426 - loss 0.61052580 - samples/sec: 368.72\n",
            "2020-04-07 09:09:40,578 epoch 8 - iter 210/426 - loss 0.60478935 - samples/sec: 475.82\n",
            "2020-04-07 09:09:43,414 epoch 8 - iter 252/426 - loss 0.60657534 - samples/sec: 479.03\n",
            "2020-04-07 09:09:46,309 epoch 8 - iter 294/426 - loss 0.60695946 - samples/sec: 468.61\n",
            "2020-04-07 09:09:49,172 epoch 8 - iter 336/426 - loss 0.60581515 - samples/sec: 474.22\n",
            "2020-04-07 09:09:52,064 epoch 8 - iter 378/426 - loss 0.60628202 - samples/sec: 469.30\n",
            "2020-04-07 09:09:54,950 epoch 8 - iter 420/426 - loss 0.60802007 - samples/sec: 470.58\n",
            "2020-04-07 09:09:55,347 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:09:55,348 EPOCH 8 done: loss 0.6109 - lr 0.1000\n",
            "2020-04-07 09:09:58,080 DEV : loss 0.9821491241455078 - score 0.5479\n",
            "Epoch     8: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-04-07 09:09:58,200 BAD EPOCHS (no improvement): 4\n",
            "2020-04-07 09:10:01,233 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:10:04,065 epoch 9 - iter 42/426 - loss 0.58670967 - samples/sec: 475.22\n",
            "2020-04-07 09:10:06,904 epoch 9 - iter 84/426 - loss 0.58924453 - samples/sec: 478.50\n",
            "2020-04-07 09:10:09,661 epoch 9 - iter 126/426 - loss 0.59096685 - samples/sec: 493.01\n",
            "2020-04-07 09:10:12,471 epoch 9 - iter 168/426 - loss 0.59722177 - samples/sec: 483.26\n",
            "2020-04-07 09:10:15,334 epoch 9 - iter 210/426 - loss 0.59640444 - samples/sec: 474.44\n",
            "2020-04-07 09:10:18,142 epoch 9 - iter 252/426 - loss 0.59147987 - samples/sec: 483.49\n",
            "2020-04-07 09:10:20,957 epoch 9 - iter 294/426 - loss 0.59506440 - samples/sec: 482.66\n",
            "2020-04-07 09:10:23,721 epoch 9 - iter 336/426 - loss 0.59739615 - samples/sec: 491.17\n",
            "2020-04-07 09:10:26,486 epoch 9 - iter 378/426 - loss 0.58923737 - samples/sec: 491.23\n",
            "2020-04-07 09:10:29,389 epoch 9 - iter 420/426 - loss 0.58778642 - samples/sec: 467.49\n",
            "2020-04-07 09:10:29,794 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:10:29,795 EPOCH 9 done: loss 0.5862 - lr 0.0500\n",
            "2020-04-07 09:10:32,576 DEV : loss 0.5875776410102844 - score 0.7813\n",
            "2020-04-07 09:10:32,700 BAD EPOCHS (no improvement): 0\n",
            "2020-04-07 09:10:38,856 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:10:41,679 epoch 10 - iter 42/426 - loss 0.59942231 - samples/sec: 476.84\n",
            "2020-04-07 09:10:44,513 epoch 10 - iter 84/426 - loss 0.59287052 - samples/sec: 479.21\n",
            "2020-04-07 09:10:47,443 epoch 10 - iter 126/426 - loss 0.58649512 - samples/sec: 463.38\n",
            "2020-04-07 09:10:50,404 epoch 10 - iter 168/426 - loss 0.58911633 - samples/sec: 458.47\n",
            "2020-04-07 09:10:53,200 epoch 10 - iter 210/426 - loss 0.58723826 - samples/sec: 485.52\n",
            "2020-04-07 09:10:56,065 epoch 10 - iter 252/426 - loss 0.58316803 - samples/sec: 473.91\n",
            "2020-04-07 09:10:58,900 epoch 10 - iter 294/426 - loss 0.57951036 - samples/sec: 478.72\n",
            "2020-04-07 09:11:01,765 epoch 10 - iter 336/426 - loss 0.57820620 - samples/sec: 474.43\n",
            "2020-04-07 09:11:04,648 epoch 10 - iter 378/426 - loss 0.57571724 - samples/sec: 470.97\n",
            "2020-04-07 09:11:07,462 epoch 10 - iter 420/426 - loss 0.57934458 - samples/sec: 482.26\n",
            "2020-04-07 09:11:07,865 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:11:07,866 EPOCH 10 done: loss 0.5786 - lr 0.0500\n",
            "2020-04-07 09:11:10,665 DEV : loss 0.605535089969635 - score 0.7719\n",
            "2020-04-07 09:11:10,789 BAD EPOCHS (no improvement): 1\n",
            "2020-04-07 09:11:13,918 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:11:16,782 epoch 11 - iter 42/426 - loss 0.59835910 - samples/sec: 470.00\n",
            "2020-04-07 09:11:19,654 epoch 11 - iter 84/426 - loss 0.56420389 - samples/sec: 472.77\n",
            "2020-04-07 09:11:22,613 epoch 11 - iter 126/426 - loss 0.56896171 - samples/sec: 458.52\n",
            "2020-04-07 09:11:25,547 epoch 11 - iter 168/426 - loss 0.57333023 - samples/sec: 462.54\n",
            "2020-04-07 09:11:28,399 epoch 11 - iter 210/426 - loss 0.58092967 - samples/sec: 476.07\n",
            "2020-04-07 09:11:31,335 epoch 11 - iter 252/426 - loss 0.57470418 - samples/sec: 462.37\n",
            "2020-04-07 09:11:34,203 epoch 11 - iter 294/426 - loss 0.57214477 - samples/sec: 473.80\n",
            "2020-04-07 09:11:37,034 epoch 11 - iter 336/426 - loss 0.57312682 - samples/sec: 479.52\n",
            "2020-04-07 09:11:39,895 epoch 11 - iter 378/426 - loss 0.57203944 - samples/sec: 474.32\n",
            "2020-04-07 09:11:42,794 epoch 11 - iter 420/426 - loss 0.57059868 - samples/sec: 468.02\n",
            "2020-04-07 09:11:43,246 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:11:43,247 EPOCH 11 done: loss 0.5716 - lr 0.0500\n",
            "2020-04-07 09:11:46,108 DEV : loss 0.7337172627449036 - score 0.6737\n",
            "2020-04-07 09:11:46,240 BAD EPOCHS (no improvement): 2\n",
            "2020-04-07 09:11:49,374 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:11:52,223 epoch 12 - iter 42/426 - loss 0.59630849 - samples/sec: 472.60\n",
            "2020-04-07 09:11:55,064 epoch 12 - iter 84/426 - loss 0.57664880 - samples/sec: 477.89\n",
            "2020-04-07 09:11:57,987 epoch 12 - iter 126/426 - loss 0.56285809 - samples/sec: 464.51\n",
            "2020-04-07 09:12:00,849 epoch 12 - iter 168/426 - loss 0.57569284 - samples/sec: 474.68\n",
            "2020-04-07 09:12:03,720 epoch 12 - iter 210/426 - loss 0.57683287 - samples/sec: 472.92\n",
            "2020-04-07 09:12:06,578 epoch 12 - iter 252/426 - loss 0.57542280 - samples/sec: 475.09\n",
            "2020-04-07 09:12:09,594 epoch 12 - iter 294/426 - loss 0.57229324 - samples/sec: 450.04\n",
            "2020-04-07 09:12:12,496 epoch 12 - iter 336/426 - loss 0.57145170 - samples/sec: 467.85\n",
            "2020-04-07 09:12:15,481 epoch 12 - iter 378/426 - loss 0.57034123 - samples/sec: 455.22\n",
            "2020-04-07 09:12:18,408 epoch 12 - iter 420/426 - loss 0.57356801 - samples/sec: 463.90\n",
            "2020-04-07 09:12:18,826 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:12:18,827 EPOCH 12 done: loss 0.5738 - lr 0.0500\n",
            "2020-04-07 09:12:21,700 DEV : loss 0.5828582644462585 - score 0.7795\n",
            "2020-04-07 09:12:21,826 BAD EPOCHS (no improvement): 3\n",
            "2020-04-07 09:12:25,008 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:12:27,848 epoch 13 - iter 42/426 - loss 0.58445304 - samples/sec: 473.93\n",
            "2020-04-07 09:12:30,796 epoch 13 - iter 84/426 - loss 0.57086408 - samples/sec: 460.37\n",
            "2020-04-07 09:12:33,659 epoch 13 - iter 126/426 - loss 0.57197892 - samples/sec: 474.70\n",
            "2020-04-07 09:12:36,548 epoch 13 - iter 168/426 - loss 0.56593380 - samples/sec: 469.54\n",
            "2020-04-07 09:12:39,408 epoch 13 - iter 210/426 - loss 0.56560807 - samples/sec: 474.88\n",
            "2020-04-07 09:12:42,259 epoch 13 - iter 252/426 - loss 0.56580920 - samples/sec: 476.14\n",
            "2020-04-07 09:12:45,177 epoch 13 - iter 294/426 - loss 0.56501127 - samples/sec: 465.53\n",
            "2020-04-07 09:12:48,099 epoch 13 - iter 336/426 - loss 0.56500809 - samples/sec: 464.43\n",
            "2020-04-07 09:12:50,976 epoch 13 - iter 378/426 - loss 0.56168069 - samples/sec: 472.33\n",
            "2020-04-07 09:12:53,978 epoch 13 - iter 420/426 - loss 0.56078691 - samples/sec: 451.83\n",
            "2020-04-07 09:12:54,412 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:12:54,413 EPOCH 13 done: loss 0.5645 - lr 0.0500\n",
            "2020-04-07 09:12:57,242 DEV : loss 0.5826258659362793 - score 0.7748\n",
            "Epoch    13: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-04-07 09:12:57,371 BAD EPOCHS (no improvement): 4\n",
            "2020-04-07 09:13:00,516 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:13:03,456 epoch 14 - iter 42/426 - loss 0.55753735 - samples/sec: 457.87\n",
            "2020-04-07 09:13:06,440 epoch 14 - iter 84/426 - loss 0.55918767 - samples/sec: 454.78\n",
            "2020-04-07 09:13:09,291 epoch 14 - iter 126/426 - loss 0.56527927 - samples/sec: 476.80\n",
            "2020-04-07 09:13:12,195 epoch 14 - iter 168/426 - loss 0.56733746 - samples/sec: 467.60\n",
            "2020-04-07 09:13:15,082 epoch 14 - iter 210/426 - loss 0.56724066 - samples/sec: 470.01\n",
            "2020-04-07 09:13:17,920 epoch 14 - iter 252/426 - loss 0.56534081 - samples/sec: 478.21\n",
            "2020-04-07 09:13:20,775 epoch 14 - iter 294/426 - loss 0.56177209 - samples/sec: 475.62\n",
            "2020-04-07 09:13:23,731 epoch 14 - iter 336/426 - loss 0.56018225 - samples/sec: 459.18\n",
            "2020-04-07 09:13:26,612 epoch 14 - iter 378/426 - loss 0.55695594 - samples/sec: 471.46\n",
            "2020-04-07 09:13:29,494 epoch 14 - iter 420/426 - loss 0.55667344 - samples/sec: 471.19\n",
            "2020-04-07 09:13:29,897 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:13:29,898 EPOCH 14 done: loss 0.5570 - lr 0.0250\n",
            "2020-04-07 09:13:32,734 DEV : loss 0.5876166820526123 - score 0.7784\n",
            "2020-04-07 09:13:32,860 BAD EPOCHS (no improvement): 1\n",
            "2020-04-07 09:13:35,984 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:13:38,842 epoch 15 - iter 42/426 - loss 0.57449383 - samples/sec: 471.06\n",
            "2020-04-07 09:13:41,709 epoch 15 - iter 84/426 - loss 0.57008963 - samples/sec: 473.74\n",
            "2020-04-07 09:13:44,632 epoch 15 - iter 126/426 - loss 0.56754798 - samples/sec: 464.35\n",
            "2020-04-07 09:13:47,576 epoch 15 - iter 168/426 - loss 0.56662814 - samples/sec: 461.09\n",
            "2020-04-07 09:13:51,342 epoch 15 - iter 210/426 - loss 0.55498843 - samples/sec: 359.52\n",
            "2020-04-07 09:13:54,208 epoch 15 - iter 252/426 - loss 0.56163133 - samples/sec: 473.53\n",
            "2020-04-07 09:13:57,116 epoch 15 - iter 294/426 - loss 0.55524685 - samples/sec: 466.96\n",
            "2020-04-07 09:14:00,034 epoch 15 - iter 336/426 - loss 0.55348498 - samples/sec: 464.80\n",
            "2020-04-07 09:14:02,892 epoch 15 - iter 378/426 - loss 0.55012814 - samples/sec: 475.33\n",
            "2020-04-07 09:14:05,855 epoch 15 - iter 420/426 - loss 0.54832966 - samples/sec: 458.01\n",
            "2020-04-07 09:14:06,240 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:14:06,241 EPOCH 15 done: loss 0.5482 - lr 0.0250\n",
            "2020-04-07 09:14:09,081 DEV : loss 0.5773307085037231 - score 0.7807\n",
            "2020-04-07 09:14:09,205 BAD EPOCHS (no improvement): 2\n",
            "2020-04-07 09:14:12,338 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:14:15,243 epoch 16 - iter 42/426 - loss 0.54874258 - samples/sec: 463.38\n",
            "2020-04-07 09:14:18,139 epoch 16 - iter 84/426 - loss 0.55813144 - samples/sec: 469.06\n",
            "2020-04-07 09:14:21,014 epoch 16 - iter 126/426 - loss 0.55975520 - samples/sec: 472.17\n",
            "2020-04-07 09:14:23,929 epoch 16 - iter 168/426 - loss 0.56058517 - samples/sec: 465.66\n",
            "2020-04-07 09:14:26,787 epoch 16 - iter 210/426 - loss 0.55449692 - samples/sec: 474.85\n",
            "2020-04-07 09:14:29,653 epoch 16 - iter 252/426 - loss 0.55319578 - samples/sec: 473.76\n",
            "2020-04-07 09:14:32,595 epoch 16 - iter 294/426 - loss 0.55088311 - samples/sec: 461.54\n",
            "2020-04-07 09:14:35,520 epoch 16 - iter 336/426 - loss 0.54877544 - samples/sec: 464.20\n",
            "2020-04-07 09:14:38,377 epoch 16 - iter 378/426 - loss 0.54982046 - samples/sec: 475.50\n",
            "2020-04-07 09:14:41,295 epoch 16 - iter 420/426 - loss 0.54785556 - samples/sec: 465.30\n",
            "2020-04-07 09:14:41,680 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:14:41,681 EPOCH 16 done: loss 0.5473 - lr 0.0250\n",
            "2020-04-07 09:14:44,514 DEV : loss 0.5751501321792603 - score 0.7848\n",
            "2020-04-07 09:14:44,642 BAD EPOCHS (no improvement): 0\n",
            "2020-04-07 09:14:51,013 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:14:53,896 epoch 17 - iter 42/426 - loss 0.56395401 - samples/sec: 466.94\n",
            "2020-04-07 09:14:56,879 epoch 17 - iter 84/426 - loss 0.55180509 - samples/sec: 455.18\n",
            "2020-04-07 09:14:59,759 epoch 17 - iter 126/426 - loss 0.54592483 - samples/sec: 471.18\n",
            "2020-04-07 09:15:02,606 epoch 17 - iter 168/426 - loss 0.54260834 - samples/sec: 477.08\n",
            "2020-04-07 09:15:05,535 epoch 17 - iter 210/426 - loss 0.54938521 - samples/sec: 463.60\n",
            "2020-04-07 09:15:08,462 epoch 17 - iter 252/426 - loss 0.54698748 - samples/sec: 463.97\n",
            "2020-04-07 09:15:11,481 epoch 17 - iter 294/426 - loss 0.54507157 - samples/sec: 449.41\n",
            "2020-04-07 09:15:14,337 epoch 17 - iter 336/426 - loss 0.54517127 - samples/sec: 475.28\n",
            "2020-04-07 09:15:17,210 epoch 17 - iter 378/426 - loss 0.54456669 - samples/sec: 472.62\n",
            "2020-04-07 09:15:20,026 epoch 17 - iter 420/426 - loss 0.54470000 - samples/sec: 482.32\n",
            "2020-04-07 09:15:20,435 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:15:20,436 EPOCH 17 done: loss 0.5445 - lr 0.0250\n",
            "2020-04-07 09:15:23,276 DEV : loss 0.5919610261917114 - score 0.7725\n",
            "2020-04-07 09:15:23,402 BAD EPOCHS (no improvement): 1\n",
            "2020-04-07 09:15:26,625 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:15:29,534 epoch 18 - iter 42/426 - loss 0.55439393 - samples/sec: 462.68\n",
            "2020-04-07 09:15:32,384 epoch 18 - iter 84/426 - loss 0.55696177 - samples/sec: 476.44\n",
            "2020-04-07 09:15:35,191 epoch 18 - iter 126/426 - loss 0.55472974 - samples/sec: 483.75\n",
            "2020-04-07 09:15:38,138 epoch 18 - iter 168/426 - loss 0.55552267 - samples/sec: 460.65\n",
            "2020-04-07 09:15:41,038 epoch 18 - iter 210/426 - loss 0.55096744 - samples/sec: 467.92\n",
            "2020-04-07 09:15:43,851 epoch 18 - iter 252/426 - loss 0.54111672 - samples/sec: 482.89\n",
            "2020-04-07 09:15:46,779 epoch 18 - iter 294/426 - loss 0.54198607 - samples/sec: 463.75\n",
            "2020-04-07 09:15:49,694 epoch 18 - iter 336/426 - loss 0.54269932 - samples/sec: 465.55\n",
            "2020-04-07 09:15:52,595 epoch 18 - iter 378/426 - loss 0.54057689 - samples/sec: 467.72\n",
            "2020-04-07 09:15:55,551 epoch 18 - iter 420/426 - loss 0.54258057 - samples/sec: 459.24\n",
            "2020-04-07 09:15:55,976 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:15:55,978 EPOCH 18 done: loss 0.5420 - lr 0.0250\n",
            "2020-04-07 09:15:58,826 DEV : loss 0.5721337199211121 - score 0.7848\n",
            "2020-04-07 09:15:58,951 BAD EPOCHS (no improvement): 2\n",
            "2020-04-07 09:16:05,156 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:16:08,040 epoch 19 - iter 42/426 - loss 0.52786256 - samples/sec: 466.77\n",
            "2020-04-07 09:16:10,883 epoch 19 - iter 84/426 - loss 0.54917463 - samples/sec: 477.79\n",
            "2020-04-07 09:16:13,859 epoch 19 - iter 126/426 - loss 0.54202108 - samples/sec: 456.70\n",
            "2020-04-07 09:16:16,753 epoch 19 - iter 168/426 - loss 0.54260684 - samples/sec: 469.32\n",
            "2020-04-07 09:16:19,662 epoch 19 - iter 210/426 - loss 0.54212914 - samples/sec: 466.90\n",
            "2020-04-07 09:16:22,548 epoch 19 - iter 252/426 - loss 0.54311594 - samples/sec: 470.40\n",
            "2020-04-07 09:16:25,450 epoch 19 - iter 294/426 - loss 0.54617565 - samples/sec: 467.91\n",
            "2020-04-07 09:16:28,294 epoch 19 - iter 336/426 - loss 0.54626985 - samples/sec: 477.72\n",
            "2020-04-07 09:16:31,283 epoch 19 - iter 378/426 - loss 0.54227394 - samples/sec: 454.25\n",
            "2020-04-07 09:16:34,202 epoch 19 - iter 420/426 - loss 0.54087764 - samples/sec: 465.25\n",
            "2020-04-07 09:16:34,637 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:16:34,639 EPOCH 19 done: loss 0.5425 - lr 0.0250\n",
            "2020-04-07 09:16:37,449 DEV : loss 0.5767635107040405 - score 0.7795\n",
            "2020-04-07 09:16:37,572 BAD EPOCHS (no improvement): 3\n",
            "2020-04-07 09:16:40,714 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:16:43,652 epoch 20 - iter 42/426 - loss 0.49322439 - samples/sec: 458.23\n",
            "2020-04-07 09:16:46,587 epoch 20 - iter 84/426 - loss 0.52518307 - samples/sec: 462.55\n",
            "2020-04-07 09:16:49,586 epoch 20 - iter 126/426 - loss 0.52609330 - samples/sec: 452.62\n",
            "2020-04-07 09:16:52,465 epoch 20 - iter 168/426 - loss 0.53132634 - samples/sec: 471.51\n",
            "2020-04-07 09:16:55,309 epoch 20 - iter 210/426 - loss 0.52939515 - samples/sec: 477.14\n",
            "2020-04-07 09:16:58,233 epoch 20 - iter 252/426 - loss 0.52729891 - samples/sec: 464.17\n",
            "2020-04-07 09:17:01,058 epoch 20 - iter 294/426 - loss 0.52384494 - samples/sec: 480.17\n",
            "2020-04-07 09:17:03,913 epoch 20 - iter 336/426 - loss 0.53298577 - samples/sec: 475.58\n",
            "2020-04-07 09:17:06,744 epoch 20 - iter 378/426 - loss 0.53388897 - samples/sec: 480.02\n",
            "2020-04-07 09:17:09,664 epoch 20 - iter 420/426 - loss 0.53776205 - samples/sec: 465.16\n",
            "2020-04-07 09:17:10,075 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:17:10,076 EPOCH 20 done: loss 0.5372 - lr 0.0250\n",
            "2020-04-07 09:17:12,910 DEV : loss 0.5883842706680298 - score 0.7701\n",
            "Epoch    20: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-04-07 09:17:13,034 BAD EPOCHS (no improvement): 4\n",
            "2020-04-07 09:17:16,177 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:17:19,080 epoch 21 - iter 42/426 - loss 0.54231632 - samples/sec: 463.53\n",
            "2020-04-07 09:17:21,920 epoch 21 - iter 84/426 - loss 0.54627331 - samples/sec: 478.45\n",
            "2020-04-07 09:17:24,764 epoch 21 - iter 126/426 - loss 0.54556259 - samples/sec: 477.64\n",
            "2020-04-07 09:17:27,681 epoch 21 - iter 168/426 - loss 0.53611416 - samples/sec: 465.33\n",
            "2020-04-07 09:17:30,599 epoch 21 - iter 210/426 - loss 0.52987503 - samples/sec: 465.14\n",
            "2020-04-07 09:17:33,524 epoch 21 - iter 252/426 - loss 0.53463411 - samples/sec: 464.57\n",
            "2020-04-07 09:17:36,497 epoch 21 - iter 294/426 - loss 0.53366099 - samples/sec: 456.59\n",
            "2020-04-07 09:17:39,461 epoch 21 - iter 336/426 - loss 0.52847713 - samples/sec: 458.33\n",
            "2020-04-07 09:17:42,321 epoch 21 - iter 378/426 - loss 0.52902569 - samples/sec: 474.86\n",
            "2020-04-07 09:17:45,265 epoch 21 - iter 420/426 - loss 0.53155044 - samples/sec: 461.16\n",
            "2020-04-07 09:17:45,681 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:17:45,683 EPOCH 21 done: loss 0.5305 - lr 0.0125\n",
            "2020-04-07 09:17:48,530 DEV : loss 0.594220757484436 - score 0.7766\n",
            "2020-04-07 09:17:48,662 BAD EPOCHS (no improvement): 1\n",
            "2020-04-07 09:17:51,818 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:17:54,702 epoch 22 - iter 42/426 - loss 0.51985125 - samples/sec: 466.90\n",
            "2020-04-07 09:17:57,678 epoch 22 - iter 84/426 - loss 0.54837918 - samples/sec: 455.41\n",
            "2020-04-07 09:18:00,565 epoch 22 - iter 126/426 - loss 0.53777830 - samples/sec: 469.99\n",
            "2020-04-07 09:18:03,428 epoch 22 - iter 168/426 - loss 0.53832688 - samples/sec: 474.62\n",
            "2020-04-07 09:18:06,359 epoch 22 - iter 210/426 - loss 0.53642674 - samples/sec: 463.06\n",
            "2020-04-07 09:18:09,265 epoch 22 - iter 252/426 - loss 0.53537613 - samples/sec: 467.24\n",
            "2020-04-07 09:18:12,948 epoch 22 - iter 294/426 - loss 0.53577257 - samples/sec: 367.93\n",
            "2020-04-07 09:18:15,882 epoch 22 - iter 336/426 - loss 0.53368466 - samples/sec: 462.67\n",
            "2020-04-07 09:18:18,798 epoch 22 - iter 378/426 - loss 0.53526049 - samples/sec: 466.05\n",
            "2020-04-07 09:18:21,700 epoch 22 - iter 420/426 - loss 0.53307620 - samples/sec: 467.90\n",
            "2020-04-07 09:18:22,088 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:18:22,090 EPOCH 22 done: loss 0.5309 - lr 0.0125\n",
            "2020-04-07 09:18:24,912 DEV : loss 0.5608702301979065 - score 0.786\n",
            "2020-04-07 09:18:25,046 BAD EPOCHS (no improvement): 0\n",
            "2020-04-07 09:18:31,367 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:18:34,216 epoch 23 - iter 42/426 - loss 0.54235784 - samples/sec: 472.68\n",
            "2020-04-07 09:18:37,152 epoch 23 - iter 84/426 - loss 0.54564493 - samples/sec: 462.43\n",
            "2020-04-07 09:18:40,107 epoch 23 - iter 126/426 - loss 0.55186808 - samples/sec: 459.13\n",
            "2020-04-07 09:18:43,016 epoch 23 - iter 168/426 - loss 0.53680577 - samples/sec: 466.67\n",
            "2020-04-07 09:18:45,919 epoch 23 - iter 210/426 - loss 0.53001265 - samples/sec: 467.69\n",
            "2020-04-07 09:18:48,814 epoch 23 - iter 252/426 - loss 0.52455440 - samples/sec: 468.92\n",
            "2020-04-07 09:18:51,664 epoch 23 - iter 294/426 - loss 0.53111576 - samples/sec: 476.69\n",
            "2020-04-07 09:18:54,505 epoch 23 - iter 336/426 - loss 0.53203342 - samples/sec: 478.26\n",
            "2020-04-07 09:18:57,458 epoch 23 - iter 378/426 - loss 0.52938772 - samples/sec: 459.67\n",
            "2020-04-07 09:19:00,367 epoch 23 - iter 420/426 - loss 0.52949409 - samples/sec: 467.03\n",
            "2020-04-07 09:19:00,791 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:19:00,792 EPOCH 23 done: loss 0.5287 - lr 0.0125\n",
            "2020-04-07 09:19:03,610 DEV : loss 0.5620166659355164 - score 0.7913\n",
            "2020-04-07 09:19:03,739 BAD EPOCHS (no improvement): 0\n",
            "2020-04-07 09:19:10,080 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:19:12,907 epoch 24 - iter 42/426 - loss 0.50028809 - samples/sec: 476.11\n",
            "2020-04-07 09:19:15,778 epoch 24 - iter 84/426 - loss 0.50951665 - samples/sec: 472.52\n",
            "2020-04-07 09:19:18,695 epoch 24 - iter 126/426 - loss 0.51244091 - samples/sec: 465.59\n",
            "2020-04-07 09:19:21,588 epoch 24 - iter 168/426 - loss 0.51770799 - samples/sec: 469.33\n",
            "2020-04-07 09:19:24,438 epoch 24 - iter 210/426 - loss 0.52169976 - samples/sec: 476.47\n",
            "2020-04-07 09:19:27,307 epoch 24 - iter 252/426 - loss 0.51940522 - samples/sec: 473.45\n",
            "2020-04-07 09:19:30,274 epoch 24 - iter 294/426 - loss 0.52309896 - samples/sec: 457.47\n",
            "2020-04-07 09:19:33,222 epoch 24 - iter 336/426 - loss 0.52117278 - samples/sec: 460.56\n",
            "2020-04-07 09:19:36,130 epoch 24 - iter 378/426 - loss 0.52182554 - samples/sec: 466.79\n",
            "2020-04-07 09:19:39,096 epoch 24 - iter 420/426 - loss 0.52380455 - samples/sec: 457.84\n",
            "2020-04-07 09:19:39,556 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:19:39,557 EPOCH 24 done: loss 0.5240 - lr 0.0125\n",
            "2020-04-07 09:19:42,409 DEV : loss 0.5655016899108887 - score 0.7889\n",
            "2020-04-07 09:19:42,535 BAD EPOCHS (no improvement): 1\n",
            "2020-04-07 09:19:45,697 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:19:48,530 epoch 25 - iter 42/426 - loss 0.57534438 - samples/sec: 475.15\n",
            "2020-04-07 09:19:51,507 epoch 25 - iter 84/426 - loss 0.55436582 - samples/sec: 456.26\n",
            "2020-04-07 09:19:54,409 epoch 25 - iter 126/426 - loss 0.54338489 - samples/sec: 467.93\n",
            "2020-04-07 09:19:57,329 epoch 25 - iter 168/426 - loss 0.53481123 - samples/sec: 465.08\n",
            "2020-04-07 09:20:00,194 epoch 25 - iter 210/426 - loss 0.53613668 - samples/sec: 474.37\n",
            "2020-04-07 09:20:03,137 epoch 25 - iter 252/426 - loss 0.53444166 - samples/sec: 461.24\n",
            "2020-04-07 09:20:05,965 epoch 25 - iter 294/426 - loss 0.53427064 - samples/sec: 480.38\n",
            "2020-04-07 09:20:08,849 epoch 25 - iter 336/426 - loss 0.53439324 - samples/sec: 471.20\n",
            "2020-04-07 09:20:11,872 epoch 25 - iter 378/426 - loss 0.53234445 - samples/sec: 449.03\n",
            "2020-04-07 09:20:14,741 epoch 25 - iter 420/426 - loss 0.53111971 - samples/sec: 473.33\n",
            "2020-04-07 09:20:15,139 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:20:15,140 EPOCH 25 done: loss 0.5308 - lr 0.0125\n",
            "2020-04-07 09:20:17,974 DEV : loss 0.562396764755249 - score 0.7866\n",
            "2020-04-07 09:20:18,100 BAD EPOCHS (no improvement): 2\n",
            "2020-04-07 09:20:24,430 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:20:24,432 Testing using best model ...\n",
            "2020-04-07 09:20:24,434 loading file best-model.pt\n",
            "2020-04-07 09:20:29,416 0.7825\t0.7825\t0.7825\n",
            "2020-04-07 09:20:29,417 \n",
            "MICRO_AVG: acc 0.6427 - f1-score 0.7825\n",
            "MACRO_AVG: acc 0.6532 - f1-score 0.7759250000000001\n",
            "HISTORY_PRESENT_ILLNESS tp: 140 - fp: 55 - fn: 163 - tn: 1343 - precision: 0.7179 - recall: 0.4620 - accuracy: 0.3911 - f1-score: 0.5622\n",
            "HOSPITAL_COURSE tp: 604 - fp: 239 - fn: 101 - tn: 757 - precision: 0.7165 - recall: 0.8567 - accuracy: 0.6398 - f1-score: 0.7804\n",
            "MEDICATIONS tp: 232 - fp: 9 - fn: 23 - tn: 1437 - precision: 0.9627 - recall: 0.9098 - accuracy: 0.8788 - f1-score: 0.9355\n",
            "PHYSICAL_EXAMINATION tp: 355 - fp: 67 - fn: 83 - tn: 1196 - precision: 0.8412 - recall: 0.8105 - accuracy: 0.7030 - f1-score: 0.8256\n",
            "2020-04-07 09:20:29,419 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.7704, device='cuda:0'),\n",
              "  tensor(0.7318, device='cuda:0'),\n",
              "  tensor(0.7251, device='cuda:0'),\n",
              "  tensor(0.6650, device='cuda:0'),\n",
              "  tensor(0.8902, device='cuda:0'),\n",
              "  tensor(0.6581, device='cuda:0'),\n",
              "  tensor(0.8220, device='cuda:0'),\n",
              "  tensor(0.9821, device='cuda:0'),\n",
              "  tensor(0.5876, device='cuda:0'),\n",
              "  tensor(0.6055, device='cuda:0'),\n",
              "  tensor(0.7337, device='cuda:0'),\n",
              "  tensor(0.5829, device='cuda:0'),\n",
              "  tensor(0.5826, device='cuda:0'),\n",
              "  tensor(0.5876, device='cuda:0'),\n",
              "  tensor(0.5773, device='cuda:0'),\n",
              "  tensor(0.5752, device='cuda:0'),\n",
              "  tensor(0.5920, device='cuda:0'),\n",
              "  tensor(0.5721, device='cuda:0'),\n",
              "  tensor(0.5768, device='cuda:0'),\n",
              "  tensor(0.5884, device='cuda:0'),\n",
              "  tensor(0.5942, device='cuda:0'),\n",
              "  tensor(0.5609, device='cuda:0'),\n",
              "  tensor(0.5620, device='cuda:0'),\n",
              "  tensor(0.5655, device='cuda:0'),\n",
              "  tensor(0.5624, device='cuda:0')],\n",
              " 'dev_score_history': [0.6467,\n",
              "  0.7125,\n",
              "  0.7108,\n",
              "  0.7454,\n",
              "  0.7125,\n",
              "  0.7366,\n",
              "  0.6649,\n",
              "  0.5479,\n",
              "  0.7813,\n",
              "  0.7719,\n",
              "  0.6737,\n",
              "  0.7795,\n",
              "  0.7748,\n",
              "  0.7784,\n",
              "  0.7807,\n",
              "  0.7848,\n",
              "  0.7725,\n",
              "  0.7848,\n",
              "  0.7795,\n",
              "  0.7701,\n",
              "  0.7766,\n",
              "  0.786,\n",
              "  0.7913,\n",
              "  0.7889,\n",
              "  0.7866],\n",
              " 'test_score': 0.7825,\n",
              " 'train_loss_history': [0.9130475886970618,\n",
              "  0.7342724016574627,\n",
              "  0.6900109798415726,\n",
              "  0.6632394094562306,\n",
              "  0.6473857867465892,\n",
              "  0.6303878263548506,\n",
              "  0.616550057356906,\n",
              "  0.6109143079656391,\n",
              "  0.5861744369279611,\n",
              "  0.578629226681772,\n",
              "  0.5715554085835605,\n",
              "  0.5738051870899021,\n",
              "  0.5645409069360702,\n",
              "  0.5570365368900164,\n",
              "  0.5481789175053717,\n",
              "  0.5472946255139901,\n",
              "  0.5444993153564247,\n",
              "  0.541984779734007,\n",
              "  0.5424973788745526,\n",
              "  0.5371871213887779,\n",
              "  0.5305344882845319,\n",
              "  0.5308688914342106,\n",
              "  0.5287022414341779,\n",
              "  0.5239556175372411,\n",
              "  0.5307749937607649]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "961NxFBNzwzt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3298514-8993-4ce2-efa1-c6a915297e7e"
      },
      "source": [
        "# 9. continue trainer at later point\n",
        "from pathlib import Path\n",
        "\n",
        "checkpoint = 'checkpoint.pt'\n",
        "trainer = ModelTrainer.load_checkpoint(checkpoint, corpus)\n",
        "trainer.train('./',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150,\n",
        "              checkpoint=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 09:50:49,997 epoch 68 - iter 420/426 - loss 0.41315776 - samples/sec: 463.02\n",
            "2020-04-07 09:50:50,422 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:50:50,424 EPOCH 68 done: loss 0.4127 - lr 0.0031\n",
            "2020-04-07 09:50:53,314 DEV : loss 0.5306460857391357 - score 0.8095\n",
            "2020-04-07 09:50:53,437 BAD EPOCHS (no improvement): 2\n",
            "2020-04-07 09:50:56,561 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:50:59,469 epoch 69 - iter 42/426 - loss 0.41139370 - samples/sec: 463.09\n",
            "2020-04-07 09:50:59,809 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:50:59,811 Exiting from training early.\n",
            "2020-04-07 09:50:59,812 Saving model ...\n",
            "2020-04-07 09:51:02,961 Done.\n",
            "2020-04-07 09:51:02,962 ----------------------------------------------------------------------------------------------------\n",
            "2020-04-07 09:51:02,966 Testing using best model ...\n",
            "2020-04-07 09:51:02,968 loading file best-model.pt\n",
            "2020-04-07 09:51:07,176 0.8036\t0.8036\t0.8036\n",
            "2020-04-07 09:51:07,178 \n",
            "MICRO_AVG: acc 0.6717 - f1-score 0.8036\n",
            "MACRO_AVG: acc 0.6852 - f1-score 0.804875\n",
            "HISTORY_PRESENT_ILLNESS tp: 178 - fp: 66 - fn: 125 - tn: 1332 - precision: 0.7295 - recall: 0.5875 - accuracy: 0.4824 - f1-score: 0.6508\n",
            "HOSPITAL_COURSE tp: 595 - fp: 199 - fn: 110 - tn: 797 - precision: 0.7494 - recall: 0.8440 - accuracy: 0.6582 - f1-score: 0.7939\n",
            "MEDICATIONS tp: 230 - fp: 10 - fn: 25 - tn: 1436 - precision: 0.9583 - recall: 0.9020 - accuracy: 0.8679 - f1-score: 0.9293\n",
            "PHYSICAL_EXAMINATION tp: 364 - fp: 59 - fn: 74 - tn: 1204 - precision: 0.8605 - recall: 0.8311 - accuracy: 0.7324 - f1-score: 0.8455\n",
            "2020-04-07 09:51:07,179 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.7655, device='cuda:0'),\n",
              "  tensor(1.0872, device='cuda:0'),\n",
              "  tensor(0.7034, device='cuda:0'),\n",
              "  tensor(0.6849, device='cuda:0'),\n",
              "  tensor(0.5749, device='cuda:0'),\n",
              "  tensor(0.6729, device='cuda:0'),\n",
              "  tensor(0.6149, device='cuda:0'),\n",
              "  tensor(0.7134, device='cuda:0'),\n",
              "  tensor(0.7969, device='cuda:0'),\n",
              "  tensor(0.5722, device='cuda:0'),\n",
              "  tensor(0.5636, device='cuda:0'),\n",
              "  tensor(0.5491, device='cuda:0'),\n",
              "  tensor(0.5716, device='cuda:0'),\n",
              "  tensor(0.5519, device='cuda:0'),\n",
              "  tensor(0.5661, device='cuda:0'),\n",
              "  tensor(0.5341, device='cuda:0'),\n",
              "  tensor(0.5569, device='cuda:0'),\n",
              "  tensor(0.5533, device='cuda:0'),\n",
              "  tensor(0.5659, device='cuda:0'),\n",
              "  tensor(0.6381, device='cuda:0'),\n",
              "  tensor(0.5411, device='cuda:0'),\n",
              "  tensor(0.5421, device='cuda:0'),\n",
              "  tensor(0.5374, device='cuda:0'),\n",
              "  tensor(0.5371, device='cuda:0'),\n",
              "  tensor(0.5573, device='cuda:0'),\n",
              "  tensor(0.5430, device='cuda:0'),\n",
              "  tensor(0.5733, device='cuda:0'),\n",
              "  tensor(0.5352, device='cuda:0'),\n",
              "  tensor(0.5335, device='cuda:0'),\n",
              "  tensor(0.5370, device='cuda:0'),\n",
              "  tensor(0.5349, device='cuda:0'),\n",
              "  tensor(0.5347, device='cuda:0'),\n",
              "  tensor(0.5353, device='cuda:0'),\n",
              "  tensor(0.5356, device='cuda:0'),\n",
              "  tensor(0.5292, device='cuda:0'),\n",
              "  tensor(0.5548, device='cuda:0'),\n",
              "  tensor(0.5349, device='cuda:0'),\n",
              "  tensor(0.5330, device='cuda:0'),\n",
              "  tensor(0.5397, device='cuda:0'),\n",
              "  tensor(0.5330, device='cuda:0'),\n",
              "  tensor(0.5348, device='cuda:0'),\n",
              "  tensor(0.5351, device='cuda:0'),\n",
              "  tensor(0.5306, device='cuda:0')],\n",
              " 'dev_score_history': [0.649,\n",
              "  0.5873,\n",
              "  0.7137,\n",
              "  0.7454,\n",
              "  0.7813,\n",
              "  0.7149,\n",
              "  0.776,\n",
              "  0.7243,\n",
              "  0.6743,\n",
              "  0.7907,\n",
              "  0.7854,\n",
              "  0.7919,\n",
              "  0.7778,\n",
              "  0.7972,\n",
              "  0.7825,\n",
              "  0.8031,\n",
              "  0.7925,\n",
              "  0.7942,\n",
              "  0.7907,\n",
              "  0.749,\n",
              "  0.796,\n",
              "  0.8031,\n",
              "  0.8048,\n",
              "  0.7989,\n",
              "  0.8013,\n",
              "  0.7989,\n",
              "  0.7895,\n",
              "  0.8072,\n",
              "  0.8107,\n",
              "  0.7995,\n",
              "  0.8054,\n",
              "  0.8078,\n",
              "  0.8125,\n",
              "  0.8048,\n",
              "  0.8066,\n",
              "  0.8013,\n",
              "  0.8019,\n",
              "  0.8119,\n",
              "  0.8089,\n",
              "  0.8107,\n",
              "  0.8119,\n",
              "  0.8066,\n",
              "  0.8095],\n",
              " 'test_score': 0.8036,\n",
              " 'train_loss_history': [0.5790449054168424,\n",
              "  0.5618708747233583,\n",
              "  0.5579415202280725,\n",
              "  0.5513116427010774,\n",
              "  0.5431307697659927,\n",
              "  0.5386343979989419,\n",
              "  0.5353368681991044,\n",
              "  0.5307833245242706,\n",
              "  0.5222161227198834,\n",
              "  0.49767034707214913,\n",
              "  0.49137168605003,\n",
              "  0.4927348600167064,\n",
              "  0.4859448602431817,\n",
              "  0.4835386271348022,\n",
              "  0.4816496387613771,\n",
              "  0.47831377243631884,\n",
              "  0.4752371728490216,\n",
              "  0.474421480312034,\n",
              "  0.46754035713946873,\n",
              "  0.46555532532538607,\n",
              "  0.45741361197731306,\n",
              "  0.448370973863792,\n",
              "  0.4490354048883971,\n",
              "  0.43960848625556964,\n",
              "  0.4412577840294077,\n",
              "  0.4442613202501351,\n",
              "  0.4442173414666888,\n",
              "  0.4328734560436766,\n",
              "  0.4351812111030162,\n",
              "  0.43588492389715894,\n",
              "  0.4286774609395316,\n",
              "  0.4270811515724715,\n",
              "  0.42946947254065615,\n",
              "  0.42289168422630696,\n",
              "  0.428634772488209,\n",
              "  0.42108599033573985,\n",
              "  0.41729883989537825,\n",
              "  0.4192720587964349,\n",
              "  0.4163680124170903,\n",
              "  0.41305790652691476,\n",
              "  0.4178070974112117,\n",
              "  0.4130976858588172,\n",
              "  0.4127196800051161]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiwWOE6fCYpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model to google drive\n",
        "!cp *.pt /content/drive/My\\ Drive/topic-segmentation/athi_dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSiE7oAuCm6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restore model from google drive\n",
        "!cp /content/drive/My\\ Drive/topic-segmentation/athi_dataset/*.pt  ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84gRn3dwwLxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "9a869ae6-09c7-450f-e44b-706489d9be87"
      },
      "source": [
        "# predictions\n",
        "import pandas as pd\n",
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "classifier = TextClassifier.load('./best-model.pt')\n",
        "\n",
        "data_te = pd.read_csv(\"./testset.csv\")\n",
        "sents = data_te['text'].tolist()\n",
        "for i, sent in enumerate(sents):\n",
        "  sentence = Sentence(sent)\n",
        "  classifier.predict(sentence)\n",
        "  row = data_te.iloc[i]\n",
        "  if sentence.labels[0].value!=row.label:\n",
        "    print(\"Sentence: \" + row.text + \" True: \" + str(row.label) + \" Pred: \" + str(sentence.labels[0]))\n",
        "  if i>100: break\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 10:04:55,865 loading file ./best-model.pt\n",
            "Sentence: DISCHARGE ORDERS : True: HOSPITAL_COURSE Pred: PHYSICAL_EXAMINATION (0.39421799778938293)\n",
            "Sentence: She is asked to call with any fevers   chills   increasing weakness or numbness or any bowel and bladder disruption . True: HOSPITAL_COURSE Pred: HISTORY_PRESENT_ILLNESS (0.9354006052017212)\n",
            "Sentence: She was discharged on the following medications . True: MEDICATIONS Pred: HOSPITAL_COURSE (0.8389503955841064)\n",
            "Sentence: HPI : True: HISTORY_PRESENT_ILLNESS Pred: PHYSICAL_EXAMINATION (0.5590241551399231)\n",
            "Sentence: ROS otherwise negative . True: HISTORY_PRESENT_ILLNESS Pred: PHYSICAL_EXAMINATION (0.45137909054756165)\n",
            "Sentence: - EKG sinus 92   no ST changes True: PHYSICAL_EXAMINATION Pred: HOSPITAL_COURSE (0.6567186713218689)\n",
            "Sentence: A / P : True: PHYSICAL_EXAMINATION Pred: HOSPITAL_COURSE (0.5507094264030457)\n",
            "Sentence: 75 y / o F with h / o COPD c / b frequent exacerbations p / w typical flare symptoms . True: PHYSICAL_EXAMINATION Pred: HISTORY_PRESENT_ILLNESS (0.6700582504272461)\n",
            "Sentence: Cr 0.8   stress incontinence by symptoms with increased cough   no evidence of uti   cont to closely monitor True: PHYSICAL_EXAMINATION Pred: HOSPITAL_COURSE (0.4759773015975952)\n",
            "Sentence: Endo - DM on insulin with steroids True: PHYSICAL_EXAMINATION Pred: HOSPITAL_COURSE (0.5542866587638855)\n",
            "Sentence: Please see your PCP in follow up . True: MEDICATIONS Pred: HOSPITAL_COURSE (0.5675868391990662)\n",
            "Sentence: This was especially bad when trying to arise . True: HISTORY_PRESENT_ILLNESS Pred: HOSPITAL_COURSE (0.7232838869094849)\n",
            "Sentence: The patient could not be moved and had to have 911 called for help . True: HISTORY_PRESENT_ILLNESS Pred: HOSPITAL_COURSE (0.6074155569076538)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrh6SoAL0DMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}